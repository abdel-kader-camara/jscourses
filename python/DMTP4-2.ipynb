{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_RealValuedColumn(column_name='', dimension=8, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmppxouvp_d\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f061197d6a0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmppxouvp_d'}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmppxouvp_d/model.ckpt.\n",
      "INFO:tensorflow:loss = 8.252223, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmppxouvp_d/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.054842103.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-10:26:24\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppxouvp_d/model.ckpt-100\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-10:26:24\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9075724, global_step = 100, loss = 0.33943626\n",
      "{'loss': 0.33943626, 'accuracy': 0.9075724, 'global_step': 100}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppxouvp_d/model.ckpt-100\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0611ade3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plot\n",
    "    \n",
    "digits = datasets.load_digits()\n",
    "training_size = int(digits.images.shape[0]/2)\n",
    "\n",
    "training_images = digits.images[0:training_size]\n",
    "training_images = training_images.reshape((training_images.shape[0], -1))\n",
    "\n",
    "training_target = digits.target[0:training_size]\n",
    "print(tf.contrib.layers.real_valued_column(\"\", dimension=8))\n",
    "\n",
    "classifier = tf.contrib.learn.DNNClassifier(\n",
    "        feature_columns=[tf.contrib.layers.real_valued_column(\"\", dtype=tf.float64)],\n",
    "        # 2  hidden layers of 50 nodes each\n",
    "        hidden_units=[50, 50],\n",
    "        # 10 classes: 0, 1, 2.....3\n",
    "         n_classes=10)\n",
    "classifier.fit(training_images, training_target, steps=100)\n",
    "\n",
    "#prediction\n",
    "predict_images = digits.images[training_size+1:]\n",
    "actual_labels = digits.target[training_size+1:]\n",
    "evaluation = classifier.evaluate(x=predict_images.reshape((predict_images.shape[0], -1)), y=actual_labels)\n",
    "print(evaluation)\n",
    "predict = classifier.predict(predict_images[16].reshape(1,-1))\n",
    "print(list(predict))\n",
    "plot.imshow(predict_images[16], cmap=plot.cm.gray_r)\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 94, 105)\n",
      "80\n",
      "66\n",
      "660000\n",
      "5e\n",
      "5e00\n",
      "69\n",
      "665e69\n",
      "6708841\n",
      "[6708841]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "imgfile = Image.open(\"flower.jpg\")\n",
    "\n",
    "imgdata = []\n",
    "for data in imgfile.getdata():\n",
    "    print(data)\n",
    "    imgdata.append(data[0] << 16 | data[1] << 8 |data[2])\n",
    "    print(format(1<<7, '02x'))\n",
    "    print(format(data[0], '02x'))\n",
    "    print(format(data[0]<<16, '02x'))\n",
    "    print(format(data[1], '02x'))\n",
    "    print(format(data[1]<<8, '02x'))\n",
    "    print(format(data[2], '02x'))\n",
    "    print(format(data[0] << 16 | data[1] << 8 |data[2], '02x'))\n",
    "    print(data[0] << 16 | data[1] << 8 |data[2])\n",
    "    print(imgdata)\n",
    "    break\n",
    "    \n",
    "numarray = numpy.array(imgdata, numpy.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "imgfile = Image.open(\"flower.jpg\")\n",
    "\n",
    "imgdata = []\n",
    "for data in imgfile.getdata():\n",
    "    imgdata.append(data[0] << 16 | data[1] << 8 |data[2])\n",
    "    break\n",
    "    \n",
    "numarray = numpy.array(imgdata, numpy.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      green       0.45      1.00      0.62         5\n",
      "     yellow       1.00      0.14      0.25         7\n",
      "\n",
      "avg / total       0.77      0.50      0.41        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy\n",
    "\n",
    "imgfile = Image.open(\"flower.jpg\")\n",
    "\n",
    "\n",
    "labels = ['green', 'green', 'yellow', 'green', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'green'\n",
    "                  ]\n",
    "\n",
    "imgdata = []\n",
    "yaxis = 0\n",
    "for i in range(0, 640, 128):\n",
    "    xaxis=0\n",
    "    for j in range(0,480, 96):\n",
    "        bbox = (i, j, i+128, j+96)\n",
    "        boxdata = []\n",
    "        for data in imgfile.crop(bbox).getdata():\n",
    "            boxdata.append(data[0] << 16 | data[1] << 8 |data[2])\n",
    "        numarray = numpy.array(boxdata, numpy.uint32)\n",
    "        imgdata.append(boxdata)\n",
    "        xaxis = xaxis + 1\n",
    "    yaxis = yaxis + 1\n",
    "\n",
    "imgdata = numpy.array(imgdata)\n",
    "\n",
    "training_size = int(imgdata.shape[0]/2)\n",
    "\n",
    "training_images = imgdata[0:training_size]\n",
    "training_images = training_images.reshape((training_images.shape[0], -1))\n",
    "\n",
    "training_target = labels[0:training_size]\n",
    "\n",
    "classifier = Perceptron(max_iter=1000)\n",
    "#classifier = MLPClassifier(alpha=2, max_iter=1000)\n",
    "#classifier = svm.SVC(gamma=0.001, C=100.)\n",
    "#classifier = Perceptron(max_iter=1000)\n",
    "\n",
    "#training\n",
    "classifier.fit(training_images, training_target)\n",
    "\n",
    "#prediction\n",
    "predict_images = imgdata[training_size+1:]\n",
    "actual_labels = labels[training_size+1:]\n",
    "predicted_labels = classifier.predict(predict_images.reshape((predict_images.shape[0], -1)))\n",
    "\n",
    "#classification report\n",
    "print(metrics.classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-61134876cfb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "training_images = data[:int(digits.images.shape[0]/2)]\n",
    "training_images = training_images.reshape((training_images.shape[0], -1))\n",
    "\n",
    "training_target = digits.target[0:int(digits.target.shape[0]/2)]\n",
    "\n",
    "classifier = Perceptron(max_iter=1000)\n",
    "#training\n",
    "classifier.fit(training_images, training_target)\n",
    "\n",
    "#prediction\n",
    "predict_images = digits.images[int(digits.images.shape[0]/2)+1:]\n",
    "actual_labels = digits.target[int(digits.target.shape[0]/2)+1:]\n",
    "predicted_labels = classifier.predict(predict_images.reshape((predict_images.shape[0], -1)))\n",
    "\n",
    "#classification report\n",
    "print(metrics.classification_report(actual_labels,predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmplexluc3s\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0606579710>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmplexluc3s'}\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmplexluc3s/model.ckpt.\n",
      "INFO:tensorflow:loss = 1953412.6, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmplexluc3s/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.69314766.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplexluc3s/model.ckpt-100\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-16:07:15\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplexluc3s/model.ckpt-100\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-16:07:15\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.25, accuracy/baseline_label_mean = 0.75, accuracy/threshold_0.500000_mean = 0.25, auc = 0.4999997, auc_precision_recall = 0.8749997, global_step = 100, labels/actual_label_mean = 0.75, labels/prediction_mean = 0.49949315, loss = 0.69365454, precision/positive_threshold_0.500000_mean = 0.0, recall/positive_threshold_0.500000_mean = 0.0\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy\n",
    "\n",
    "imgfile = Image.open(\"flower.jpg\")\n",
    "\n",
    "\n",
    "labels = ['green', 'green', 'yellow', 'green', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'green'\n",
    "                  ]\n",
    "\n",
    "for i in range(0,len(labels)):\n",
    "    if(labels[i] == 'green'):\n",
    "        labels[i] = 0\n",
    "    else:\n",
    "        labels[i] = 1\n",
    "\n",
    "imgdata = []\n",
    "yaxis = 0\n",
    "for i in range(0, 640, 128):\n",
    "    xaxis=0\n",
    "    for j in range(0,480, 96):\n",
    "        bbox = (i, j, i+128, j+96)\n",
    "        boxdata = []\n",
    "        for data in imgfile.crop(bbox).getdata():\n",
    "            boxdata.append(data[0] << 16 | data[1] << 8 |data[2])\n",
    "        numarray = numpy.array(boxdata, numpy.uint32)\n",
    "        imgdata.append(boxdata)\n",
    "        xaxis = xaxis + 1\n",
    "    yaxis = yaxis + 1\n",
    "\n",
    "imgdata = numpy.array(imgdata)\n",
    "\n",
    "training_size = int(imgdata.shape[0]/2) + 8\n",
    "\n",
    "training_images = imgdata[0:training_size]\n",
    "training_images = training_images.reshape((training_images.shape[0], -1))\n",
    "\n",
    "training_target = labels[0:training_size]\n",
    "\n",
    "classifier = tf.contrib.learn.DNNClassifier(\n",
    "     feature_columns=[tf.contrib.layers.real_valued_column(\"\", dtype=tf.int8)],\n",
    "     # 2 hidden layers of 10 nodes each\n",
    "     hidden_units=[10, 10, 10],\n",
    "     # 2 classes\n",
    "     n_classes=2)\n",
    "\n",
    "\n",
    "#training\n",
    "classifier.fit(training_images, training_target, steps=100)\n",
    "\n",
    "#prediction\n",
    "predict_images = imgdata[training_size+1:]\n",
    "actual_labels = labels[training_size+1:]\n",
    "predicted_labels = classifier.predict(predict_images.reshape((predict_images.shape[0], -1)))\n",
    "evaluation = classifier.evaluate(x=predict_images.reshape((predict_images.shape[0], -1)), y=actual_labels)\n",
    "print(evaluation['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp3oq1_gtd\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0606093c88>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmp3oq1_gtd'}\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp3oq1_gtd/model.ckpt.\n",
      "INFO:tensorflow:loss = 4244435.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 231.883\n",
      "INFO:tensorflow:loss = 42813.48, step = 101 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.537\n",
      "INFO:tensorflow:loss = 6572.095, step = 201 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.454\n",
      "INFO:tensorflow:loss = 3672.2727, step = 301 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.942\n",
      "INFO:tensorflow:loss = 156.654, step = 401 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.743\n",
      "INFO:tensorflow:loss = 105.68923, step = 501 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.334\n",
      "INFO:tensorflow:loss = 42.899807, step = 601 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.508\n",
      "INFO:tensorflow:loss = 23.755577, step = 701 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.913\n",
      "INFO:tensorflow:loss = 18.173107, step = 801 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.09\n",
      "INFO:tensorflow:loss = 13.948339, step = 901 (0.508 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp3oq1_gtd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.3734374.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-16:30:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp3oq1_gtd/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-16:30:02\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.31578946, accuracy/baseline_label_mean = 0.47368422, accuracy/threshold_0.500000_mean = 0.31578946, auc = 0.31111112, auc_precision_recall = 0.42032164, global_step = 1000, labels/actual_label_mean = 0.47368422, labels/prediction_mean = 0.42105263, loss = 7673.517, precision/positive_threshold_0.500000_mean = 0.25, recall/positive_threshold_0.500000_mean = 0.22222222\n",
      "0.31578946\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy\n",
    "\n",
    "imgfile = Image.open(\"flower.jpg\")\n",
    "\n",
    "\n",
    "labels = ['green', 'green', 'green', 'green', 'yellow', 'green', 'green', 'green', 'green', 'green',\n",
    "                   'green', 'green', 'green', 'green', 'yellow', 'yellow', 'green', 'green', 'green', 'green',\n",
    "                   'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'green', 'yellow', 'yellow', 'green', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green',\n",
    "                   'green', 'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'green', 'yellow', 'yellow', 'green', 'yellow', 'green', 'green', 'green'\n",
    "                  ]\n",
    "\n",
    "\n",
    "for i in range(0,len(labels)):\n",
    "    if(labels[i] == 'green'):\n",
    "        labels[i] = 0\n",
    "    else:\n",
    "        labels[i] = 1\n",
    "\n",
    "imgdata = []\n",
    "yaxis = 0\n",
    "for i in range(0, 640, 64):\n",
    "    xaxis=0\n",
    "    for j in range(0,480, 48):\n",
    "        bbox = (i, j, i+64, j+48)\n",
    "        boxdata = []\n",
    "        for data in imgfile.crop(bbox).getdata():\n",
    "            boxdata.append(data[0] << 16 | data[1] << 8 |data[2])\n",
    "        numarray = numpy.array(boxdata, numpy.int64)\n",
    "        imgdata.append(boxdata)\n",
    "        xaxis = xaxis + 1\n",
    "    yaxis = yaxis + 1\n",
    "\n",
    "imgdata = numpy.array(imgdata)\n",
    "\n",
    "training_size = int(imgdata.shape[0]/2) + 30\n",
    "\n",
    "training_images = imgdata[0:training_size]\n",
    "training_images = training_images.reshape((training_images.shape[0], -1))\n",
    "\n",
    "training_target = labels[0:training_size]\n",
    "\n",
    "classifier = tf.contrib.learn.DNNClassifier(\n",
    "     feature_columns=[tf.contrib.layers.real_valued_column(\"\", dtype=tf.int8)],\n",
    "     # 2 hidden layers of 10 nodes each\n",
    "     hidden_units=[20, 20, 20, 20],\n",
    "     # 2 classes\n",
    "     n_classes=2)\n",
    "\n",
    "\n",
    "#training\n",
    "classifier.fit(training_images, training_target, steps=1000)\n",
    "\n",
    "#prediction\n",
    "predict_images = imgdata[training_size+1:]\n",
    "actual_labels = labels[training_size+1:]\n",
    "evaluation = classifier.evaluate(x=predict_images.reshape((predict_images.shape[0], -1)), y=actual_labels)\n",
    "print(evaluation['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      green       0.50      0.60      0.55        10\n",
      "     yellow       0.43      0.33      0.38         9\n",
      "\n",
      "avg / total       0.47      0.47      0.46        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy\n",
    "\n",
    "imgfile = Image.open(\"flower.jpg\")\n",
    "\n",
    "\n",
    "labels = ['green', 'green', 'green', 'green', 'yellow', 'green', 'green', 'green', 'green', 'green',\n",
    "                   'green', 'green', 'green', 'green', 'yellow', 'yellow', 'green', 'green', 'green', 'green',\n",
    "                   'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'green', 'yellow', 'yellow', 'green', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green',\n",
    "                   'green', 'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green',\n",
    "                   'green', 'green', 'green', 'yellow', 'yellow', 'green', 'yellow', 'green', 'green', 'green'\n",
    "                  ]\n",
    "\n",
    "imgdata = []\n",
    "yaxis = 0\n",
    "for i in range(0, 640, 64):\n",
    "    xaxis=0\n",
    "    for j in range(0,480, 48):\n",
    "        bbox = (i, j, i+64, j+48)\n",
    "        boxdata = []\n",
    "        for data in imgfile.crop(bbox).getdata():\n",
    "            boxdata.append(data[0] << 16 | data[1] << 8 |data[2])\n",
    "        numarray = numpy.array(boxdata, numpy.uint32)\n",
    "        imgdata.append(boxdata)\n",
    "        xaxis = xaxis + 1\n",
    "    yaxis = yaxis + 1\n",
    "\n",
    "imgdata = numpy.array(imgdata)\n",
    "\n",
    "training_size = int(imgdata.shape[0]/2) + 30\n",
    "\n",
    "training_images = imgdata[0:training_size]\n",
    "training_images = training_images.reshape((training_images.shape[0], -1))\n",
    "\n",
    "training_target = labels[0:training_size]\n",
    "\n",
    "classifier = Perceptron(max_iter=1000)\n",
    "#classifier = MLPClassifier(alpha=2, max_iter=1000)\n",
    "#classifier = svm.SVC(gamma=0.001, C=100.)\n",
    "#classifier = Perceptron(max_iter=1000)\n",
    "\n",
    "#training\n",
    "classifier.fit(training_images, training_target)\n",
    "\n",
    "#prediction\n",
    "predict_images = imgdata[training_size+1:]\n",
    "actual_labels = labels[training_size+1:]\n",
    "predicted_labels = classifier.predict(predict_images.reshape((predict_images.shape[0], -1)))\n",
    "\n",
    "#classification report\n",
    "print(metrics.classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"user\": \"user 1\", \"colors\": [[120, 30, 120], [150, 30, 10]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "colors = [[120, 30, 120], [150, 30, 10]]\n",
    "user = \"user 1\"\n",
    "\n",
    "data = dict()\n",
    "data['user'] = user\n",
    "data['colors'] = colors\n",
    "\n",
    "print(json.dumps(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "colors = [[120, 30, 120], [150, 30, 10]]\n",
    "user = \"user 1\"\n",
    "\n",
    "data = dict()\n",
    "data['user'] = user\n",
    "data['colors'] = colors\n",
    "\n",
    "with open(\"user.json\", \"w\") as file:\n",
    "    json.dump(data, file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'user 1', 'colors': [[120, 30, 120], [150, 30, 10]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = \"\"\n",
    "with open(\"user.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
